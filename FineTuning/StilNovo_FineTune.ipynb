{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Choice",
   "id": "14c42c4ed4f32e79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Various options considered given hardware constaints (running on Macbook, 16GB RAM):\n",
    "- Tiny LLaMA\n",
    "- Phi-1.5\n",
    "- Pythia 1.4B\n",
    "- Phi-2 (can possibly tune with QLoRA, but slow)\n",
    "- Zephyr 1.3B\n",
    "- Yi-3B (perhaps, with offload)\n",
    "- Geppetto GP-2\n",
    "\n",
    "Phi-1.5/2 is a more modern model trained for high performance on reasoning tasks.\n",
    "\n",
    "TinYLLaMA is a smaller model trained for edge devices, protyping etc.\n",
    "\n",
    "Pythia is slightly outdated, but it was trained on a more diverse vocabulary from web text and should do better for stylistic text generation like poetry. It was trained on english only text, not ideal for italian text generation.\n",
    "\n",
    "Zephyr was trained in english, but it's fairly good at text generation\n",
    "\n",
    "Yi is a more powerful model, trained on some italian partially. Training might be very slow\n",
    "\n",
    "Gepptetto is a model trained on italian text, but it's old and very outdated.\n",
    "\n",
    "-------------------------\n",
    "\n",
    "- Try with Zephyr to start --> it was very slow and could barely fit inside the RAM of the computer.\n",
    "\n",
    "- I decided to move to TinyLLaMA since it is a smaller model and easier to train on a laptop.\n",
    "\n"
   ],
   "id": "e0c131d59e70e74f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-26T15:46:30.864490Z",
     "start_time": "2025-04-26T15:46:30.801153Z"
    }
   },
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import einops\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Use MPS if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel, PeftConfig"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T01:03:52.875473Z",
     "start_time": "2025-04-26T01:03:40.952553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# using the tinyllama model\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\" #\"stabilityai/stablelm-2-zephyr-1_6b\"\n",
    "\n",
    "# Use the tokenizer for the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token # add eos_token (not present in the tinyllama tokenizer by default)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map={\"\": \"mps\"},\n",
    "    torch_dtype=\"float32\",  # mps does not support float16, bfloat16. i wish it did\n",
    "    trust_remote_code=True\n",
    ")\n"
   ],
   "id": "5f6b3216a6ca14b1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T01:03:53.709398Z",
     "start_time": "2025-04-26T01:03:52.926966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare LoRA with PEFT\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, # Language modeling\n",
    "    inference_mode=False, # set to True for inference, False for training\n",
    "    r=8, # Rank of LoRA matrices. Higher rank gives more capacity to adapt, but is slower and requires more computational resources\n",
    "    lora_alpha=16, # Scaling factor. Affects how much the LoRA weights \"influence\" the base model. Typically alpha = 2×r is a good default.\n",
    "    lora_dropout=0.1 # Dropout during training\n",
    ")\n",
    "\n",
    "# Apply LoRA adapters\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# check that the only trainable parameters are the LoRA ones\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(\"Trainable:\", name)\n"
   ],
   "id": "7f3381d7c7a2226a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "Trainable: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "Trainable: base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "Trainable: base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T01:03:59.969164Z",
     "start_time": "2025-04-26T01:03:59.962447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## create the corpus of text used for training\n",
    "read_data = False\n",
    "if read_data: # already have the corpus preprocessed\n",
    "    with open('corpus_cleaned.txt', 'r', encoding='utf-8') as f:\n",
    "        corpus = f.read()\n",
    "else:\n",
    "    # import the text data\n",
    "    os.chdir('data')\n",
    "\n",
    "    corpus = ''\n",
    "    # read the texts\n",
    "    for file in ['cavalcanti_poems_cleaned.txt','Dante_Divina_Commedia_final_cleaned.txt','il_canzoniere_petrarca_cleaned.txt']:\n",
    "        if file.endswith(\".txt\"):\n",
    "            text = open(file, 'r', encoding='utf-8').read()\n",
    "            corpus += text\n",
    "            # print(text[:100])\n",
    "\n",
    "    os.chdir('..') # go back 1 lavel higher"
   ],
   "id": "68dc904d397c9f0c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T01:04:02.506734Z",
     "start_time": "2025-04-26T01:04:02.502846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Combine all into one list of canto strings (feeding the model with a nicely formatted data should help it learn better)\n",
    "def extract_cantos(text):\n",
    "    cantos = []\n",
    "    lines = text.strip().splitlines()\n",
    "    buffer = []\n",
    "    in_canto = False\n",
    "    for line in lines:\n",
    "        if line.strip() == \"<canto>\":\n",
    "            buffer = []\n",
    "            in_canto = True\n",
    "        elif line.strip() == \"</canto>\":\n",
    "            if buffer:\n",
    "                cantos.append(\"\\n\".join(buffer))\n",
    "            in_canto = False\n",
    "        elif in_canto:\n",
    "            buffer.append(line.strip())\n",
    "    return cantos\n",
    "\n",
    "need_to_generate_data = False\n",
    "if need_to_generate_data:\n",
    "    all_cantos = extract_cantos(corpus)\n",
    "    # Save as JSONL\n",
    "    jsonl_path = \"italian_poetry_dataset.jsonl\"\n",
    "    with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for canto in all_cantos:\n",
    "            json.dump({\"text\": f\"<canto>\\n{canto}\\n</canto>\"}, f, ensure_ascii=False)\n",
    "            f.write(\"\\n\")\n"
   ],
   "id": "ffb22d6e314118d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T01:04:05.544623Z",
     "start_time": "2025-04-26T01:04:05.045591Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91ee12fd9360428b96b47e9db1cf20ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training samples: 476\n"
     ]
    }
   ],
   "execution_count": 8,
   "source": [
    "## create the dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# === Load dataset ===\n",
    "dataset = load_dataset(\"json\", data_files='italian_poetry_dataset.jsonl', split=\"train\")\n",
    "\n",
    "# === Tokenize the dataset ===\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128) # higher max len could be helpful to improve the ability of the model to maintain coherence over longer context lengths, but it also requires more memory (which is a bottleneck given I am using a laptop)\n",
    "\n",
    "tokenized_ds = dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# === Define data collator ===\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# === Training args ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./tinyllama-poetry-lora\",\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=5,\n",
    "    gradient_accumulation_steps=4,\n",
    "    eval_strategy =\"no\",\n",
    "    save_steps=100,\n",
    "    logging_steps=30,\n",
    "    fp16=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    report_to=\"none\",\n",
    "    overwrite_output_dir=True\n",
    ")\n",
    "\n",
    "print(f\"# of training samples: {len(tokenized_ds)}\")\n"
   ],
   "id": "c10ed6645cdbf58c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:42:41.139945Z",
     "start_time": "2025-04-26T15:42:00.361371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## test time of training 1 batch\n",
    "import time\n",
    "# Set model to train mode\n",
    "model.train()\n",
    "\n",
    "# Grab a single example from your tokenized dataset\n",
    "example = tokenized_ds[0]\n",
    "input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(\"mps\")  # shape: [1, seq_len]\n",
    "attention_mask = torch.tensor(example[\"attention_mask\"]).unsqueeze(0).to(\"mps\")\n",
    "labels = input_ids.clone()\n",
    "\n",
    "# Warm-up pass (optional but good for MPS)\n",
    "for _ in range(2):\n",
    "    _ = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "# Benchmark\n",
    "start = time.time()\n",
    "output = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "loss = output.loss\n",
    "loss.backward()\n",
    "end = time.time()\n",
    "\n",
    "print(f\"⏱️ One batch (forward + backward) took: {end - start:.2f} seconds\")\n"
   ],
   "id": "b1ead28b284e49a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️ One batch (forward + backward) took: 13.30 seconds\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The duration of one batch is about 0.5 seconds on my macbook when things go well. Depending on what else is running, time can vary a lot.",
   "id": "507ebd3023b61596"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T01:15:22.231810Z",
     "start_time": "2025-04-26T01:04:22.610784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Train ===\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "prev_checkpoint = None #\"./zephyr-poetry-lora/checkpoint-357\"\n",
    "if prev_checkpoint:\n",
    "    trainer.train(resume_from_checkpoint=prev_checkpoint)\n",
    "else:\n",
    "    trainer.train()"
   ],
   "id": "aacf62e97a03e339",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4g/bd8qcn0d0w33my4q6djs6csw0000gn/T/ipykernel_16928/828098516.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [595/595 10:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.079700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.957900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.801200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.702300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.633100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.627900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.618300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.628700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.582800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.606200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.575100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.557900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.579500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.553800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.561500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.584300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T16:08:27.791625Z",
     "start_time": "2025-04-26T16:08:27.426066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## plot the loss vs step\n",
    "import matplotlib.pyplot as plt\n",
    "steps = [30, 120, 210, 300, 390, 480, 570]\n",
    "losses = [4.08, 3.73, 3.63, 3.62, 3.61, 3.58, 3.58]\n",
    "\n",
    "plt.semilogy(steps,losses)\n",
    "plt.show()"
   ],
   "id": "f766aca80eb49885",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T03:32:08.127401Z",
     "start_time": "2025-04-26T03:31:24.750876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## testing the model\n",
    "# Load base model and tokenizer\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\" #\"stabilityai/stablelm-2-zephyr-1_6b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map={\"\": \"mps\"},\n",
    "    torch_dtype=torch.float32,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load PEFT configuration and adapter\n",
    "peft_model = PeftModel.from_pretrained(base_model, \"./zephyr-poetry-lora/checkpoint-595\")\n",
    "peft_model.eval()\n"
   ],
   "id": "24a3dd0b11e77189",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-21): 22 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "              (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:33:16.719465Z",
     "start_time": "2025-04-26T15:33:16.619576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# custom stopping\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "# === Define custom stopping rule\n",
    "class StopOnCantoEnd(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, stop_sequence=\"</canto>\"):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stop_ids = tokenizer(stop_sequence, add_special_tokens=False).input_ids\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        # Check if the last tokens match stop_sequence\n",
    "        if input_ids.shape[1] < len(self.stop_ids):\n",
    "            return False\n",
    "        return (input_ids[0, -len(self.stop_ids):] == torch.tensor(self.stop_ids, device=input_ids.device)).all()\n"
   ],
   "id": "f1201a3d4307d2ef",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:39:08.681243Z",
     "start_time": "2025-04-26T15:38:08.979806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Setup generation\n",
    "prompt = \"Inizia il canto:\\n<canto>\\nNel mezzo del cammin di nostra vita\\n\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"mps\")\n",
    "\n",
    "# Attach stopping criteria\n",
    "stopping_criteria = StoppingCriteriaList([\n",
    "    StopOnCantoEnd(tokenizer)\n",
    "])\n",
    "\n",
    "# === Generate!\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=500,  # Set a safety limit in case model goes crazy\n",
    "        temperature=1.0,\n",
    "        top_p=0.95,\n",
    "        do_sample=True,\n",
    "        stopping_criteria=stopping_criteria\n",
    "    )\n",
    "\n",
    "# === Decode and print\n",
    "generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"📝 Generated Canto:\\n\")\n",
    "print(generated)"
   ],
   "id": "6a420f08c9beeda6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Generated Canto:\n",
      "\n",
      "Inizia il canto:\n",
      "<canto>\n",
      "Nel mezzo del cammin di nostra vita\n",
      "mi sono fermata per dire\n",
      "che il più triste cor amando,\n",
      "che la terra vagheggia,\n",
      "quale mai in sé o in altri\n",
      "sogna con dolce vista\n",
      "ch'erel che la vita si farla\n",
      "m'arrende et inancio\n",
      "per voler morir nella tua giù?\n",
      "O meno, ché di noi nessuno son\n",
      "che non si vada avanti in terra,\n",
      "ch'ascolta, et la vita che fegleggia,\n",
      "ch'alzata in alto farli riemper\n",
      "al di là per cui amà\n",
      "quello altr'altro et ne' sentir\n",
      "onde fie ch'ad esser triste\n",
      "ch'erel che vivi et inancio\n",
      "che si dever in vita avrebbe?\n",
      "Non tanto quanto d'ogni gusto\n",
      "ch'e' per sempre e' 'gni, per\n",
      "di noi s'ascolta, che son\n",
      "o mal avendo, o sano altr'altro.\n",
      "Nell'altra gesto et nell'altro mio\n",
      "alto s'intorno, et s'invecchio\n",
      "d'amor, et di paure, et di sciolte\n",
      "et d'alt'alt'alt'alt'alt'alt'alt'altro;\n",
      "ché tesserai et a tua luce\n",
      "d'et non di me, che noi s'innamor\n",
      "per un'onesta lagrima, et la roba\n",
      "che i nostri dolci sensi desider,\n",
      "tanto et sempre ch'e' per sempre\n",
      "et inancio.\n",
      "Chi, per il vostro cor, noi si ama,\n",
      "per 'l tuo pensoso, per 'l tuo gusto,\n",
      "quando 'l vostro amore e' perverse?\n",
      "Mira a tutt'alt'alt'alt'alt'alt'alt'altro,\n",
      "et chi la tua vostra paura penso\n",
      "sint chiaro et sempre in te.\n",
      "Che d'un pensiero d'erarvevole\n",
      "tanta gente noi ne' luoghi et ne' soli\n",
      "m\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Not too bad. The text definitely sounds like old italian, and the rough style was transferred. More complex patterns (like the rhyme scheme, keeping things into 'terzina's or the general length of an individual canto) are still missing, perhas using a model with more capacity could help.",
   "id": "e55220a6aaaabafe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T16:00:06.465048Z",
     "start_time": "2025-04-26T15:59:06.639835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### For comparison, the tinyllama without fine tuning would do this:\n",
    "# === Load the original TinyLlama model\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map={\"\": \"mps\"},\n",
    "    torch_dtype=torch.float32,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# === Prepare the same prompt\n",
    "prompt = \"Inizia il canto:\\n<canto>\\nNel mezzo del cammin di nostra vita\\n\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"mps\")\n",
    "\n",
    "# === Generate without LoRA\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=300,\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"📝 Base TinyLlama Output (No LoRA):\\n\")\n",
    "print(generated)"
   ],
   "id": "972439f98d0748c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Base TinyLlama Output (No LoRA):\n",
      "\n",
      "Inizia il canto:\n",
      "<canto>\n",
      "Nel mezzo del cammin di nostra vita\n",
      "Mi prospetto nella penna incorniciata\n",
      "Di un grande ciondolo di lusso\n",
      "Da te, lussuriosa eterne stanza,\n",
      "Vuoi portarmi a fondo nell'imbarazzo?\n",
      "\n",
      "<re>\n",
      "Mai avrà la tua voce mai sonoramente\n",
      "Giunsi a me lanciata al suono d'oro.\n",
      "Non vi ha in lusso mai avuto l'occhio\n",
      "A tollerare il malgoverno del mondo?\n",
      "Se è possibile nella mia sottomissione\n",
      "Di lusinghe eterne stanzie\n",
      "Da te come un pezzo di scrittura legna il mio\n",
      "Nuovo capolavoro, pungente e onesta donna,\n",
      "Non sevi di questo che te mi piacere,\n",
      "Il coro, il suono d'alcune vocali\n",
      "\n",
      "Sui mille angeli da cui ti esce un'alba\n",
      "Sonore e in pace e in silenzio lontana\n",
      "M'avete portato a fondo in te,\n",
      "Come nell'ultimo silenzio, il sole,\n",
      "In terra eterna e in cielo\n",
      "Di parole l'oracolo che stanno per dirmi:\n",
      "\n",
      "\n",
      "\n",
      "<re>\n",
      "Sono la verità in te, che\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The default tinyllama sounds like modern italian, it does not use any of the mannerisms that you would see in old italian poetry. It also capitalizes the first letter of each line, even when it should not. The rhyme scheme is also missing.\n",
    "We can see that the LoRA helped infuse some of the poetic style into the model. It's still not perfect, but it's a big step forward."
   ],
   "id": "3e4a4f0510c1c044"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "45b7531424d00111"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
