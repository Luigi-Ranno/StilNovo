{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:16:53.690738Z",
     "start_time": "2025-04-26T18:16:53.687999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import einops\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Use MPS if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n"
   ],
   "id": "8b7a0f9f7ac768ea",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:16:54.061449Z",
     "start_time": "2025-04-26T18:16:54.048818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate/read corpus\n",
    "read_data = False\n",
    "if read_data: # already have the corpus preprocessed\n",
    "    with open('corpus.txt', 'r', encoding='utf-8') as f:\n",
    "        corpus = f.read()\n",
    "else:\n",
    "    # import the text data\n",
    "    os.chdir('data')\n",
    "\n",
    "    corpus = ''\n",
    "    # read the texts\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".txt\"):\n",
    "            text = open(file, 'r', encoding='utf-8').read()\n",
    "            corpus += text\n",
    "            # print(text[:100])\n",
    "\n",
    "    os.chdir('..') # go back 1 lavel higher"
   ],
   "id": "2e18e8cf1184592d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The first step is to tokenize the corpus. We will use the ByteLevelBPETokenizer from the tokenizers library.\n",
    "A Byte-Level Tokenizer (sometimes called byte pair, byte fallback, or byte encoding) works at the byte level of text, rather than working directly at the word, character, or Unicode codepoint level.\n",
    "It sees text as raw bytes (0–255 values) and tokenizes based on byte patterns."
   ],
   "id": "f01ffd7386f09f58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Every input text is first split into bytes (ASCII / UTF-8).\n",
    "Common byte patterns (e.g., 'tion', 'pre', 'com', etc.) are merged into bigger tokens.\n",
    "Rare characters or unusual sequences can fall back to raw bytes if necessary (no tokenization errors).\n",
    "Example:\n",
    "\"Dante\" → might be tokenized into something like ['D', 'ant', 'e'] or individual bytes depending on training."
   ],
   "id": "5f998ab82330edc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Byte-level tokenizers can handle any text (good so that if ever see a rare character, there are no issues).\n",
    "They are relatively good at handling noisy data (e.g. typos)\n",
    "But it can create more tokens per sentence (depending on the vocab size selected), and it can take a bit to train.\n",
    "\n",
    "\n",
    "\n",
    "Another tokenizer that is popular is SentencePiece, which is trained on a corpus and then generates a vocabulary of subwords. Given that the text I am training on uses a lot of archaic words and lots of word diversity in general, BPE is probably the best option."
   ],
   "id": "c3b8d9c952afb880"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:16:56.258621Z",
     "start_time": "2025-04-26T18:16:56.233101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## tokenizer\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "train=False\n",
    "if train:\n",
    "    # Train the tokenizer\n",
    "    vocab_size = 3000\n",
    "\n",
    "    # Save your full corpus string to a file\n",
    "    with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(corpus)\n",
    "\n",
    "    tokenizer = ByteLevelBPETokenizer()\n",
    "    tokenizer.train(files=\"corpus.txt\", vocab_size=vocab_size, min_frequency=2)\n",
    "\n",
    "\n",
    "    # Encode a sentence and test\n",
    "    encoded = tokenizer.encode(\"Nel mezzo del cammin di nostra vita\")\n",
    "    print(\"Token IDs:\", encoded.ids)\n",
    "    print(\"Tokens:   \", encoded.tokens)\n",
    "\n",
    "    decoded = tokenizer.decode(encoded.ids)\n",
    "    print(\"Decoded:  \", decoded)\n",
    "\n",
    "    # Ensure directory exists\n",
    "    os.makedirs(\"poet_tokenizer\", exist_ok=True)\n",
    "\n",
    "    # Save vocab + merges files to a directory\n",
    "    tokenizer.save_model(\"poet_tokenizer\")\n",
    "\n",
    "else:\n",
    "    tokenizer = ByteLevelBPETokenizer(\n",
    "        \"poet_tokenizer/vocab.json\",\n",
    "        \"poet_tokenizer/merges.txt\"\n",
    "    )\n"
   ],
   "id": "5bd91594264054ea",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:16:58.440490Z",
     "start_time": "2025-04-26T18:16:57.246685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenize the text\n",
    "tokens = tokenizer.encode(corpus).ids"
   ],
   "id": "17c023fbfaaea8ca",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:17:01.227428Z",
     "start_time": "2025-04-26T18:16:59.504956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create inputs and targets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "context_length = 128  #\n",
    "\n",
    "stride = context_length//16  # No overlap. Shift the window by 1/16 of the context length\n",
    "inputs = []\n",
    "targets = []\n",
    "for i in range(0, len(tokens) - context_length, stride):\n",
    "    x = tokens[i : i + context_length]\n",
    "    y = tokens[i + 1 : i + context_length + 1]\n",
    "    inputs.append(torch.tensor(x, dtype=torch.long))\n",
    "    targets.append(torch.tensor(y, dtype=torch.long))\n",
    "\n",
    "# create the dataset\n",
    "class PoetDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "dataset = PoetDataset(inputs, targets)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "7d0715f8d553bfe2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For positional encoding, I will use RoPE\n",
    "RoPE is a technique to add positional information to tokens inside the attention mechanism — without using big positional embeddings.\n",
    "\n",
    "- Instead of adding absolute positional embeddings (like in GPT-2), RoPE rotates the query and key vectors in a special way depending on the token position.\n",
    "\n",
    "It was introduced in the RoFormer paper (Su et al., 2021, https://arxiv.org/abs/2104.09864).\n",
    "\n",
    "### Why RoPE?\n",
    "In transformers: Attention is permutation-invariant (it doesn't know token order naturally).\n",
    "To model sequences, you must inject position information somehow.\n",
    "\n",
    "- Old solution: Add learned positional embeddings to token embeddings (e.g., GPT-2, BERT).\n",
    "- RoPE solution: Instead of adding extra vectors, rotate the queries and keys based on position → implicit position information inside attention itself. The RoPE imposes the rotation such that the separation between tokens is the only thing that dictates the added angle between the rotated vectors.\n",
    "\n",
    "RoPE Works better with long sequences, and is more memory efficient\n",
    "\n",
    "\n",
    "### How RoPE works\n",
    "At every layer:\n",
    "You compute query (q) and key (k) vectors normally.\n",
    "Then apply a rotation to these vectors depending on the token's position i.\n",
    "The rotation is a simple 2D complex rotation:\n",
    "\n",
    "$q[i] = q[i] * \\cos(\\theta[i]) + Rotate(q[i]) * \\sin(\\theta[i])$\n",
    "\n",
    "$k[i] = k[i] * \\cos(\\theta[i]) + Rotate(k[i]) * \\sin(\\theta[i])$\n",
    "\n",
    "where Rotate(x) flips even/odd dimensions:\n",
    "even dims: x_even\n",
    "odd dims: x_odd\n",
    "and $\\theta[i]$ is a precomputed frequency that depends on the position.\n",
    "So queries and keys \"encode\" position through their angles.\n",
    "\n",
    "\n",
    "### Pros/Cons of RoPE\n",
    "- Pros:\n",
    "    - Extrapolates to longer contexts\n",
    "    - Memory efficient\n",
    "    - Simple math, cheap to compute\n",
    "    - Works better for long-text generation, where need to attend many tokens away from one another\n",
    "- Cons:\n",
    "    - Harder to interpret than positional embeddings\n",
    "    - Not trivial to modify (if you want to shift positions, you need to recompute the angles)\n",
    "    - Not ideal for masked or shuffled sequences (for BERT, for example)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "77cb4f9ccd3556f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# RoPE\n",
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, theta: float, d_k: int, max_seq_len: int, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.theta = theta              # Θ: a hyperparameter (usually 10,000), controls frequency scaling\n",
    "        self.d_k = d_k                  # Dimensionality of each head (must be even)\n",
    "        self.max_seq_len = max_seq_len  # Maximum sequence length the model will support\n",
    "\n",
    "        # Create a tensor of positions from 0 to max_seq_len - 1\n",
    "        idx = torch.arange(0, max_seq_len, device=device, dtype=torch.float32)  # shape: (max_seq_len,)\n",
    "\n",
    "        # Compute the scaling denominator for each pair of dimensions (0, 2, 4, ..., d_k-2)\n",
    "        # This comes from the formula θ_{i,k} = i / Θ^{2k/d_k}, matching sinusoidal positional encoding scaling\n",
    "        denom = theta ** (torch.arange(0, d_k, 2, device=device, dtype=torch.float32) / d_k)  # shape: (d_k // 2,)\n",
    "\n",
    "        # Broadcast i / Θ^{2k/d} to get θ_{i,k}, shape: (max_seq_len, d_k // 2)\n",
    "        theta_i_k = idx.unsqueeze(1) / denom.unsqueeze(0)\n",
    "\n",
    "        # Precompute cos(θ_{i,k}) and sin(θ_{i,k}), used during forward pass\n",
    "        cos_cache = torch.cos(theta_i_k)  # shape: (max_seq_len, d_k // 2)\n",
    "        sin_cache = torch.sin(theta_i_k)\n",
    "\n",
    "        # Register as non-persistent buffers (they won’t be saved in model checkpoints)\n",
    "        self.register_buffer(\"cos_cache\", cos_cache, persistent=False)\n",
    "        self.register_buffer(\"sin_cache\", sin_cache, persistent=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, token_positions: torch.Tensor=None) -> torch.Tensor:\n",
    "        # x: (batch_size, seq_len, d_k)\n",
    "        seq_len = x.shape[-2]\n",
    "        d_k = x.shape[-1]\n",
    "        assert d_k % 2 == 0          # Rotation requires even dimension (so we can split into pairs)\n",
    "        assert d_k == self.d_k       # Input must match expected dimension\n",
    "\n",
    "        # Get cos/sin values for the given token positions (custom for padding/masking)\n",
    "        if token_positions is not None:\n",
    "            cos_values = self.cos_cache[token_positions, :]  # (batch, seq_len, d_k // 2)\n",
    "            sin_values = self.sin_cache[token_positions, :]\n",
    "        else:\n",
    "            # Use first `seq_len` positions from cache\n",
    "            cos_values = self.cos_cache[:seq_len, :]         # (seq_len, d_k // 2)\n",
    "            sin_values = self.sin_cache[:seq_len, :]\n",
    "\n",
    "        # Rearrange the input tensor to group even/odd values into 2D pairs\n",
    "        # x shape: (..., seq_len, d_k)\n",
    "        # becomes: (..., seq_len, d_k // 2, 2), where last dim = [even, odd]\n",
    "        x_split = einops.rearrange(\n",
    "            x, \"... seq_len (d_split pair) -> ... seq_len d_split pair\",\n",
    "            d_split=self.d_k // 2, pair=2\n",
    "        )\n",
    "        even_x = x_split[..., 0]  # shape: (..., seq_len, d_k // 2), x_{2j}\n",
    "        odd_x = x_split[..., 1]  # shape: (..., seq_len, d_k // 2), x_{2j+1}\n",
    "\n",
    "        # Apply the 2x2 rotation matrix to each [even, odd] pair:\n",
    "        # [x_even'] = cos * x_even - sin * x_odd\n",
    "        # [x_odd']  = sin * x_even + cos * x_odd\n",
    "        x_rotate_even = even_x * cos_values - odd_x * sin_values  # shape: (..., seq_len, d_k // 2)\n",
    "        x_rotate_odd  = even_x * sin_values + odd_x * cos_values\n",
    "\n",
    "        # Stack even and odd components back into shape (..., seq_len, d_k // 2, 2)\n",
    "        x_rotated = torch.stack([x_rotate_even, x_rotate_odd], dim=-1)\n",
    "\n",
    "        # Flatten last two dims to get back original shape (..., seq_len, d_k)\n",
    "        x_rotated = einops.rearrange(\n",
    "            x_rotated, \"... seq_len d_split pair -> ... seq_len (d_split pair)\",\n",
    "            d_split=self.d_k // 2, pair=2\n",
    "        )\n",
    "\n",
    "        return x_rotated\n"
   ],
   "id": "5f9b8baee0ff731f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A key layer that underpins the transformer architecture is the Multi-Head Self-Attention (MHSA) layer.\n",
    "## Multi-Head Self-Attention"
   ],
   "id": "4f7e2bc44a0bcb82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Multi-Head Self-Attention is the main mechanism that lets a transformer:\n",
    "\n",
    "Look at different parts of a sequence at the same time\n",
    "\n",
    "Mix information from different positions flexibly\n",
    "\n",
    "Capture different types of relationships (short-term, long-term, syntactic, semantic)\n",
    "- Instead of just one \"attention,\" you have many attention heads\n",
    "- Each head learns different attention patterns independently --> The model learns more patterns, more flexibly\n",
    "\n",
    "### How MHSA Works (High-level view)\n",
    "1. Compute Queries, Keys and Values (Matrices)\n",
    "2. For each head, project the inputs to queries, keys and values; Apply RoPE\n",
    "3. Compute the scaled dot product attention between queries and keys: score = $  \\frac{QK^T}{\\sqrt{d_k}}$ ($d_k$ is the dimension of the queries)\n",
    "4. Apply masking, to avoid words coming in the future from influencing the current word. Then apply softmax to the scores to find the attention weights\n",
    "5. Compute the new vector by applying the attention weights to the values, then concatanate the results in a new vector in the embedding dimension that now has been influenced by the words around it\n",
    "6. Apply a final linear layer to project the new vector into the embedding dimension, creating the output of MHSA\n",
    "\n",
    "\n",
    "### Advantages of MHSA\n",
    "- Each head can focus on a specific kind of relationship between words (e.g. gender, plural vs singular, subject, verb, emotional tone, etc.)\n",
    "- Some heads can focus on long-range dependencies, while others focus on short-range dependencies\n",
    "- All computations happen in parallel, making it very efficient to run across multiple GPUs\n",
    "\n",
    "But, need to be aware of computation (scales with O(seq_len$^2$ * $d_{embded}$)) and memory (scales like O(seq_len$^2$)). For long sequences, exploration of flash attention, Performer, longformer etc. is being investigated to improve performance"
   ],
   "id": "d993895b6c8ce772"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:17:45.425784Z",
     "start_time": "2025-04-26T18:17:45.416758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, n_heads, n_embd, dropout=0.1, rope=None, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        assert n_embd % n_heads == 0\n",
    "        self.n_heads = n_heads\n",
    "        self.head_size = n_embd // n_heads\n",
    "\n",
    "        self.qkv_proj = nn.Linear(n_embd, 3 * n_embd, device=device, dtype=dtype) # can compute the Q,K,V matrices all in 1 matrix mult, more efficient\n",
    "        self.out_proj = nn.Linear(n_embd, n_embd,device=device, dtype=dtype)\n",
    "        self.dropout = nn.Dropout(dropout,)\n",
    "        self.rms_norm = nn.RMSNorm(n_embd,device=device, dtype=dtype)\n",
    "\n",
    "        self.rope = rope  # Optional RotaryPositionalEmbedding instance\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        B, T, C = x.shape\n",
    "        x = self.rms_norm(x)\n",
    "\n",
    "        qkv = self.qkv_proj(x)  # (B, T, 3C)\n",
    "        Q, K, V = qkv.chunk(3, dim=-1)  # Each: (B, T, C)\n",
    "\n",
    "        Q = einops.rearrange(Q, 'B T (h d) -> B h T d', h=self.n_heads)\n",
    "        K = einops.rearrange(K, 'B T (h d) -> B h T d', h=self.n_heads)\n",
    "        V = einops.rearrange(V, 'B T (h d) -> B h T d', h=self.n_heads)\n",
    "\n",
    "        # Apply RoPE if available\n",
    "        if self.rope is not None:\n",
    "            Q = Q.reshape(-1, T, self.head_size)\n",
    "            K = K.reshape(-1, T, self.head_size)\n",
    "            Q = self.rope(Q)\n",
    "            K = self.rope(K)\n",
    "            Q = Q.view(B, self.n_heads, T, self.head_size)\n",
    "            K = K.view(B, self.n_heads, T, self.head_size)\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_size ** 0.5)  # (B, h, T, T)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, V)  # (B, h, T, d)\n",
    "        out = einops.rearrange(out, 'B h T d -> B T (h d)')\n",
    "        return self.out_proj(out)"
   ],
   "id": "c60074cbe8c5b573",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Feedforward using SwiGLU activation\n",
    "After MHSA, feedforward is performed using SwiGLU activation, which is a variant of the GLU activation that uses a sigmoid function to control the input and output of the feedforward layer.\n",
    "\n",
    "The reason to have a FF layer is that after self-attention, the model has mixed and exchanged information across all tokens, but each token needs more non-linear transformation individually — to refine, filter, compress, or enhance what it \"learned\". It adds expressiveness beyond just linear attention mixing, it allows model to model very rich internal features (sharp transformations).\n",
    "\n",
    "The FF works by:\n",
    "- Take the token embedding output from self-attention.\n",
    "- Pass it through a small MLP (multi-layer perceptron):\n",
    "- Expand the hidden dimension: (e.g., 4x commonly)\n",
    "- Apply a nonlinearity (activation function).\n",
    "- Project back down to original size\n",
    "\n",
    "#### Why SwiGLU specifically?\n",
    "SwiGLU = SiLU activation + gating mechanism\n",
    "It improves over older activations like ReLU, GELU by introducing a soft gating mechanism.\n",
    "- SwiGLU lets neurons softly \"turn on/off\" information, not just push it forward blindly.\n",
    "- SiLU is smooth (continuous derivative), no sharp cutoffs like ReLU\n",
    "- Empirically proven: LLaMA, PaLM, Mistral, Zephyr — all switched to SwiGLU for better training stability and final quality.\n",
    "- Deep transformers (30–80 layers) become easier to train with SwiGLU\n"
   ],
   "id": "f7bef7fd6f8f6c75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SwiGLU(nn.Module): #SwiGLU feedforward\n",
    "    def __init__(self,d_model,d_ff,dropout=0.1,device=None, dtype=None):\n",
    "        super().__init__()\n",
    "\n",
    "        if d_ff is None:\n",
    "            d_ff = (8 / 3) * d_model\n",
    "            d_ff = 64 * math.ceil(d_ff / 64)\n",
    "\n",
    "        self.W1 = nn.Parameter( torch.empty(d_ff, d_model , device=device, dtype=dtype ) )\n",
    "        self.W3 = nn.Parameter( torch.empty(d_ff, d_model, device=device, dtype=dtype  ) )\n",
    "        self.W2 = nn.Parameter( torch.empty( d_model, d_ff  ,device=device, dtype=dtype) )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        std = torch.sqrt(torch.tensor(2/(d_model + d_ff), device=device, dtype=dtype))\n",
    "\n",
    "        torch.nn.init.trunc_normal_(self.W1, mean=0, std= std, a=-3*std, b = 3*std )\n",
    "        torch.nn.init.trunc_normal_(self.W3, mean=0, std= std, a=-3*std, b = 3*std )\n",
    "        torch.nn.init.trunc_normal_(self.W2, mean=0, std= std, a=-3*std, b = 3*std )\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        p1 = F.silu(x @ self.W1.transpose(-2, -1))\n",
    "\n",
    "        p2 = x @ self.W3.transpose(-2,-1)\n",
    "\n",
    "        p2 *= p1 # elementwise multiplication\n",
    "        return self.dropout(p2 @ self.W2.transpose(-2,-1))\n"
   ],
   "id": "fb44a6b603c2f9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Language Model\n",
    "Putting everything together, into transformer blocks, and ultimately a transformer language model.\n",
    "Note that as the input propagates through the transformer, there are skip connections to make training easier and avoid vanishing gradients."
   ],
   "id": "9ff7be30b6c8a864"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:17:10.792425Z",
     "start_time": "2025-04-26T18:17:10.780574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define layers of the Language Model\n",
    "\n",
    "class Encoder_Block(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, n_heads, dropout=0.1, rope=None,device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.RMSNorm(d_model, device=device, dtype=dtype)\n",
    "        self.norm2 = nn.RMSNorm(d_model, device=device, dtype=dtype)\n",
    "        self.attn = MultiHeadSelfAttention(n_heads=n_heads, n_embd=d_model,rope=rope, dropout=dropout,device=device, dtype=dtype)\n",
    "        self.ff = SwiGLU(d_model=d_model,d_ff=d_ff,dropout=dropout,device=device, dtype=dtype)\n",
    "\n",
    "    def forward(self, x,mask=None):\n",
    "        x = x + self.attn(self.norm1(x),mask=mask)\n",
    "        x = x + self.ff(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class TransformerLM(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512, n_heads=8, num_layers=6, max_len=context_length, dropout=0.1, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_embed = nn.Embedding(vocab_size, d_model, device=device, dtype=dtype)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        rope = RotaryPositionalEmbedding(theta=10000, d_k=d_model//n_heads, max_seq_len=max_len, device=device)\n",
    "\n",
    "        self.blocks = nn.ModuleList(  [Encoder_Block(d_model=d_model, d_ff=None, n_heads=n_heads, dropout=dropout, rope=rope, device=device, dtype=dtype) for _ in range(num_layers)])\n",
    "\n",
    "        self.out_proj = nn.Linear(d_model, vocab_size)\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(max_len, max_len, device=device)).view(1, 1, max_len, max_len)) # lower triangular matrix. Precompute the mask once, and keep it stored in the model's buffer.\n",
    "    def forward(self, input_ids):\n",
    "        B, T = input_ids.shape # batch size, seq len\n",
    "        x = self.token_embed(input_ids)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        mask = self.mask[:, :, :T, :T]\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x,mask=mask)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, input_ids, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        self.eval()\n",
    "        for _ in range(max_new_tokens):\n",
    "            if input_ids.size(1) > self.mask.size(-1):\n",
    "                input_ids = input_ids[:, -self.mask.size(-1):]  # truncate left\n",
    "\n",
    "            logits = self(input_ids)  # (B, T, vocab_size)\n",
    "            logits = logits[:, -1, :] / temperature  # take logits from last time step\n",
    "\n",
    "            if top_k is not None:\n",
    "                top_k_logits, _ = torch.topk(logits, top_k)\n",
    "                logits[logits < top_k_logits[:, [-1]]] = -float('Inf')\n",
    "\n",
    "            probs = torch.softmax(logits.clamp(-100, 100), dim=-1) # (B, vocab_size). Clamp to avoid NaNs\n",
    "            next_token = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "        return input_ids\n"
   ],
   "id": "69a1405d60441c23",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create the model",
   "id": "d105a48924318292"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T04:54:40.989155Z",
     "start_time": "2025-04-24T04:54:40.913307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== Hyperparameters =====\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "d_model = 256\n",
    "n_heads = 4\n",
    "num_layers = 4\n",
    "context_length = 128\n",
    "learning_rate = 3e-4\n",
    "num_epochs = 1\n",
    "\n",
    "# ===== Instantiate the Model =====\n",
    "model = TransformerLM(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=d_model,\n",
    "    n_heads=n_heads,\n",
    "    num_layers=num_layers,\n",
    "    max_len=context_length,\n",
    "    device=device,\n",
    "    dtype= torch.float32 # torch.float16 gives bug during training, it does not work on mps # torch.bfloat16 # bloat16 not available on mps\n",
    ").to(device)\n",
    "\n",
    "# ===== Loss and Optimizer =====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n"
   ],
   "id": "c365ca0861aadd8d",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check that everything is on the correct device",
   "id": "dfe1ff96935ec25e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T04:54:41.483755Z",
     "start_time": "2025-04-24T04:54:41.480941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check that the model is on the correct device\n",
    "def check_model_device(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.device != device:\n",
    "            print(f\"[PARAM] {name} is on {param.device}, expected {device}\")\n",
    "    for name, buf in model.named_buffers():\n",
    "        if buf.device != device:\n",
    "            print(f\"[BUFFER] {name} is on {buf.device}, expected {device}\")\n",
    "\n",
    "check_model_device(model)"
   ],
   "id": "52010582a3e4165c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARAM] token_embed.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.0.norm1.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.0.norm2.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.0.attn.qkv_proj.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.0.attn.qkv_proj.bias is on mps:0, expected mps\n",
      "[PARAM] blocks.0.attn.out_proj.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.0.attn.out_proj.bias is on mps:0, expected mps\n",
      "[PARAM] blocks.0.attn.rms_norm.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.0.ff.W1 is on mps:0, expected mps\n",
      "[PARAM] blocks.0.ff.W3 is on mps:0, expected mps\n",
      "[PARAM] blocks.0.ff.W2 is on mps:0, expected mps\n",
      "[PARAM] blocks.1.norm1.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.1.norm2.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.1.attn.qkv_proj.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.1.attn.qkv_proj.bias is on mps:0, expected mps\n",
      "[PARAM] blocks.1.attn.out_proj.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.1.attn.out_proj.bias is on mps:0, expected mps\n",
      "[PARAM] blocks.1.attn.rms_norm.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.1.ff.W1 is on mps:0, expected mps\n",
      "[PARAM] blocks.1.ff.W3 is on mps:0, expected mps\n",
      "[PARAM] blocks.1.ff.W2 is on mps:0, expected mps\n",
      "[PARAM] blocks.2.norm1.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.2.norm2.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.2.attn.qkv_proj.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.2.attn.qkv_proj.bias is on mps:0, expected mps\n",
      "[PARAM] blocks.2.attn.out_proj.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.2.attn.out_proj.bias is on mps:0, expected mps\n",
      "[PARAM] blocks.2.attn.rms_norm.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.2.ff.W1 is on mps:0, expected mps\n",
      "[PARAM] blocks.2.ff.W3 is on mps:0, expected mps\n",
      "[PARAM] blocks.2.ff.W2 is on mps:0, expected mps\n",
      "[PARAM] blocks.3.norm1.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.3.norm2.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.3.attn.qkv_proj.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.3.attn.qkv_proj.bias is on mps:0, expected mps\n",
      "[PARAM] blocks.3.attn.out_proj.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.3.attn.out_proj.bias is on mps:0, expected mps\n",
      "[PARAM] blocks.3.attn.rms_norm.weight is on mps:0, expected mps\n",
      "[PARAM] blocks.3.ff.W1 is on mps:0, expected mps\n",
      "[PARAM] blocks.3.ff.W3 is on mps:0, expected mps\n",
      "[PARAM] blocks.3.ff.W2 is on mps:0, expected mps\n",
      "[PARAM] out_proj.weight is on mps:0, expected mps\n",
      "[PARAM] out_proj.bias is on mps:0, expected mps\n",
      "[BUFFER] mask is on mps:0, expected mps\n",
      "[BUFFER] blocks.0.attn.rope.cos_cache is on mps:0, expected mps\n",
      "[BUFFER] blocks.0.attn.rope.sin_cache is on mps:0, expected mps\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "5eb29c0fadf245f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T05:02:21.601900Z",
     "start_time": "2025-04-24T04:59:16.120616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== Training Loop =====\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "print(f\"# of samples: {len(dataset)} | Batch size: {batch_size} | Expected batches: {len(dataloader)}\")\n",
    "\n",
    "generate_every = 30  # generate every X batches\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    pbar = tqdm.tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    total_loss = 0\n",
    "    print(f\"Starting training loop with {len(dataloader)} batches per epoch\")\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        # print(f\"Batch {batch_idx}/{len(dataloader)}\", end='\\r')\n",
    "        # t0 = time.time()\n",
    "        input_batch, target_batch = batch\n",
    "        input_batch = input_batch.to(device)     # shape: (B, T)\n",
    "        target_batch = target_batch.to(device)   # shape: (B, T)\n",
    "        # print(f\"Batch {batch_idx} took {time.time() - t0:.2f}s to load and move\", flush=True)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(input_batch)              # shape: (B, T, vocab_size)\n",
    "        loss = criterion(logits.view(-1, vocab_size), target_batch.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\"Triggering sample generation at batch 0...\")\n",
    "            model.eval()\n",
    "            start_text = \"Nel mezzo\"\n",
    "            start_ids = tokenizer.encode(start_text).ids  #just the token IDs\n",
    "            input_ids = torch.tensor([start_ids], device=device)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_new_tokens=50,\n",
    "                temperature=1.0,\n",
    "                top_k=20\n",
    "            )\n",
    "\n",
    "            decoded = tokenizer.decode(generated_ids[0].tolist())\n",
    "            print(f\"\\n[Sample @ epoch {epoch+1}, batch {batch_idx}]\\n{decoded}\\n\")\n",
    "            model.train()\n",
    "\n",
    "\n",
    "        if batch_idx % generate_every == 0 and batch_idx > 0:\n",
    "            model.eval()\n",
    "            start_text = \"Nel mezzo\"\n",
    "            start_ids = tokenizer.encode(start_text).ids\n",
    "            input_ids = torch.tensor([start_ids], device=device)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_new_tokens=50,\n",
    "                temperature=1.0,\n",
    "                top_k=20\n",
    "            )\n",
    "\n",
    "            decoded = tokenizer.decode(generated_ids[0].tolist())\n",
    "            print(f\"\\n[Sample @ epoch {epoch+1}, batch {batch_idx}]\\n{decoded}\\n\")\n",
    "            model.train()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1} finished. Average loss: {avg_loss:.4f}\")\n",
    "\n"
   ],
   "id": "300edfa3382f7c29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples: 42986 | Batch size: 32 | Expected batches: 1344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/1344 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training loop with 1344 batches per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/1344 [00:00<?, ?it/s, loss=3.42]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triggering sample generation at batch 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 1/1344 [00:02<1:00:00,  2.68s/it, loss=3.42]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 0]\n",
      "Nel mezzo ’l cielo;\n",
      "so che già son per li altri motto,\n",
      "di tante foglie, ma ’l tuo non move,\n",
      "\n",
      "di fuor di qua da noi si diserra».\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Canto XLIV\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   2%|▏         | 32/1344 [00:07<07:36,  2.87it/s, loss=3.46] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 30]\n",
      "Nel mezzo cerchio.\n",
      "\n",
      "Di vïolle nebbia con le stelle,\n",
      "e la pioggia, e più non saggiato,\n",
      "ch’io dissi: «O tu, se’ tu ’l buon Tomena a me non m’in\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   5%|▍         | 62/1344 [00:10<06:44,  3.17it/s, loss=3.42]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 60]\n",
      "Nel mezzo,\n",
      "non per color ch’elli in su la gran fascia;\n",
      "\n",
      "ma poi, come quei, sem veduto il petto\n",
      "più ch’ogne vergogna la sete, e non s’affi\n",
      "m’affetto di me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   7%|▋         | 92/1344 [00:14<07:08,  2.92it/s, loss=3.37]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 90]\n",
      "Nel mezzo,\n",
      "et non pur a Dio, né d'invola.\n",
      "\n",
      "\n",
      "40\n",
      "\n",
      "-  madonna pensando non fosse in loco,\n",
      "che m'avendo a la lingua, et l'auro,\n",
      "che mi\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   9%|▉         | 122/1344 [00:18<06:38,  3.07it/s, loss=3.52]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 120]\n",
      "Nel mezzo giorno\n",
      "e ’l disio del cielo allarderno inferenza,\n",
      "che la qualunque si può esser non s’abbandona.\n",
      "\n",
      "E come quei che non sa chiedi!”\n",
      "Certo non pur con le sue\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  11%|█▏        | 152/1344 [00:22<06:57,  2.86it/s, loss=3.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 150]\n",
      "Nel mezzo\n",
      "nel primo, che, di sé si raggia,\n",
      "e di Calè di Carlo, e di qua e Zeno,\n",
      "e di Scrismilia, di Cocito, Sucia,\n",
      "poi\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  14%|█▎        | 182/1344 [00:26<06:14,  3.10it/s, loss=3.36]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 180]\n",
      "Nel mezzo\n",
      "per dar di sé onde pareva i denti,\n",
      "infin ch’io nol potei in questa pesa,\n",
      "\n",
      "non sarà mai sotto, ma per voi sola\n",
      "non fosse alcun, perché da lei si noma,\n",
      "e\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  16%|█▌        | 212/1344 [00:30<06:49,  2.77it/s, loss=3.47]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 210]\n",
      "Nel mezzo giorno atteno.\n",
      "\n",
      "A quella parte che 'n cielo, in suo valore\n",
      "miserere: or veggio di lei s'ài sdegno;\n",
      "ché ben m'à oggi, e 'l cor lasso riede il vero;\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  18%|█▊        | 242/1344 [00:35<07:07,  2.58it/s, loss=3.42]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 240]\n",
      "Nel mezzo;\n",
      "No, in Poco e Albero a Troiellio.\n",
      "\n",
      "E quando futurico, e non vide\n",
      "per che ’n su la gente che ’l mondo serra,\n",
      "di che i’\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  20%|██        | 272/1344 [00:39<05:21,  3.34it/s, loss=3.44]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 270]\n",
      "Nel mezzo\n",
      "ch'io dagli occhi mirando il mio foco affrena;\n",
      "et per me non fia quel ch'i' mi diedi\n",
      "i miei pensier' che sí bei inchina;\n",
      "la mia speranza de la sua luce\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  22%|██▏       | 302/1344 [00:43<05:53,  2.95it/s, loss=3.32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 300]\n",
      "Nel mezzo,\n",
      "\n",
      "per li occhi e con un’acqua e scender la roccia,\n",
      "che fece l’orlo a la Bramagna,\n",
      "fin che tu l’unghie a quel che s’affisse.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  25%|██▍       | 332/1344 [00:47<05:28,  3.08it/s, loss=3.29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 330]\n",
      "Nel mezzo,\n",
      "in te, che ’l tempo, ch’i’ mi ritrai,\n",
      "\n",
      "per lui sicurtà di fuor da eletti\n",
      "ciò che ’l viso non t’avrei disfaccia,\n",
      "non pur mo\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  27%|██▋       | 361/1344 [00:51<05:32,  2.95it/s, loss=3.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 360]\n",
      "Nel mezzo\n",
      "dietro a’ miei, che di sé largi,\n",
      "e tutti in su la ripa dura,\n",
      "\n",
      "tanto che si conversi percuopre la cima\n",
      "di là sù, che ’l sol ti facesse\n",
      "libene\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  29%|██▉       | 392/1344 [00:56<05:14,  3.02it/s, loss=3.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 390]\n",
      "Nel mezzo;\n",
      "et chi me, come in su l'aura scontra.\n",
      "\n",
      "\n",
      "335\n",
      "\n",
      "Dompirto in un punto le fonca,\n",
      "dimmi oltra: - Non sotèrado,\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  31%|███▏      | 422/1344 [01:00<04:55,  3.12it/s, loss=3.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 420]\n",
      "Nel mezzo del monte\n",
      "per un canternai mirabil, e 'l suo lume, un lauro\n",
      "col sfaccender tela, e 'l parlar che mai nol posso,\n",
      "come a te, ch'io sento il ciel saldo\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  34%|███▎      | 452/1344 [01:04<05:14,  2.83it/s, loss=3.22]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 450]\n",
      "Nel mezzo\n",
      "da nessun per suo piacer di me l'altro accusale;\n",
      "et s'io veggio in lei che 'l tempo dura\n",
      "stutte adver l'onde sian fornito.\n",
      "\n",
      "Piú ch'al\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  36%|███▌      | 482/1344 [01:08<04:48,  2.98it/s, loss=3.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 480]\n",
      "Nel mezzo,\n",
      "et quel dí in piú la vista al cielo,\n",
      "che di mille sospiri in ogni radice.\n",
      "\n",
      "Dico ch'io sempre ragiono il mio core,\n",
      "tutte, onde spera ogni vertute,\n",
      "che del mio non è\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  38%|███▊      | 512/1344 [01:11<03:56,  3.51it/s, loss=3.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 510]\n",
      "Nel mezzo;\n",
      "\n",
      "ch'al mondo non poterò com'io l'òra,\n",
      "che l'aura mia, s'a veder vorrei\n",
      "la segua, e l'alma, che 'l mondo fama si ringra;\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  40%|████      | 542/1344 [01:15<04:07,  3.25it/s, loss=3.15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 540]\n",
      "Nel mezzo spira\n",
      "e di quel ch’i’ credea che mi vinse il petto;\n",
      "e poi ch’i’ fu’ lassi ’l senso\n",
      "può di lor: “Maria la sua radice, e tu mi vedi\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  43%|████▎     | 572/1344 [01:20<04:54,  2.62it/s, loss=3.05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 570]\n",
      "Nel mezzo\n",
      "sì che le sue sante fronde sparte.\n",
      "\n",
      "Passo, che Dio s’alcuna à posto infernella\n",
      "che le prime creature in sù l’ali,\n",
      "non per voi par che tu non vedi intero;\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  45%|████▍     | 602/1344 [01:24<04:38,  2.66it/s, loss=3.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 600]\n",
      "Nel mezzo 'l mar che 'n subitamente;\n",
      "\n",
      "l'alma súbito celeste, che per mio albergo\n",
      "lasselosïata dal cor mi doglio et taccia,\n",
      "sí lieve non già mai né pie' cr\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  47%|████▋     | 632/1344 [01:28<04:23,  2.70it/s, loss=3.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 630]\n",
      "Nel mezzo nove,\n",
      "\n",
      "e che ’l mondo ha di Dio s’intrina,\n",
      "sì che ’l principio de la terra ond’ elli stette,\n",
      "e di giù di ciò che m’apparìco;\n",
      "\n",
      "ma\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  49%|████▉     | 662/1344 [01:33<04:09,  2.73it/s, loss=3.09]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 660]\n",
      "Nel mezzo\n",
      "là dove appar più non s’arresta;\n",
      "ma non è più che ’l mondo non s’ascoso,\n",
      "ma non per altro che non si parean li tondi:\n",
      "\n",
      "però fu così mi parvor\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  51%|█████▏    | 692/1344 [01:37<03:09,  3.43it/s, loss=3.15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 690]\n",
      "Nel mezzo\n",
      "per l’uom di là da Dio che si provide.\n",
      "\n",
      "Finito questo e li è più d’i ciocchi;\n",
      "vedi come è più che si distria;\n",
      "però t’è utito ad\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  54%|█████▎    | 722/1344 [01:41<03:13,  3.22it/s, loss=3.16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 720]\n",
      "Nel mezzo\n",
      "punfo da la lingua e ’l marito,\n",
      "e li occhi avea di sé trasmutava\n",
      "in tutto ciò che ’l mondo ha fatto.\n",
      "\n",
      "Non pur a parlar pregava e ’l ciel miro;\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  56%|█████▌    | 752/1344 [01:45<03:25,  2.88it/s, loss=3.07]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 750]\n",
      "Nel mezzo\n",
      "de la sua virtù che per lei si riga,\n",
      "infin che, se tu vuol che tu mi vinse,\n",
      "\n",
      "per questa altezza fatta che di tirandi\n",
      "e che ’n questo mondo in sé lunga guerra\n",
      "come\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  58%|█████▊    | 782/1344 [01:49<03:27,  2.70it/s, loss=3.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 780]\n",
      "Nel mezzo\n",
      "per l'un per mio mal mio fastro,\n",
      "e 'l bel viso e 'l riso de le gemme\n",
      "con le sue stelle, e 'l bel lume spento\n",
      "che madonna non súbito piú,\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  60%|██████    | 812/1344 [01:53<03:09,  2.81it/s, loss=3.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 810]\n",
      "Nel mezzo\n",
      "l’amor che ’l viso a la cogna giace,\n",
      "\n",
      "così di quelli in sùbita v’era la costa;\n",
      "e io in qua, sì tutto s’avvenire\n",
      "e l’animo ad amante a\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  63%|██████▎   | 842/1344 [01:57<02:50,  2.95it/s, loss=3.02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 840]\n",
      "Nel mezzo,\n",
      "ch’e’ non furon maggior sete o vede accesa,\n",
      "\n",
      "ma ne’ corustanturosi e sanza legge\n",
      "l’umana natura, e ’l serpente\n",
      "là dove il suo fa venire il mena;\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  65%|██████▍   | 872/1344 [02:01<02:27,  3.19it/s, loss=3]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 870]\n",
      "Nel mezzo\n",
      "per lo viso che ’n dietro ad avessi lece.\n",
      "\n",
      "E la dimanda a la sua madre\n",
      "de l’un d’arume ch’elli intende,\n",
      "che già non potevan d’ira son quelle genti\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  67%|██████▋   | 902/1344 [02:05<02:33,  2.89it/s, loss=2.99]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 900]\n",
      "Nel mezzo 'l volto.\n",
      "Gal mondo, che s'appavaratonda, et l'alma è vinto.\n",
      "\n",
      "Siava i rami scende ovunque alberga\n",
      "un'ombra di foco, e di desire\n",
      "se\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  69%|██████▉   | 932/1344 [02:09<02:25,  2.83it/s, loss=2.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 930]\n",
      "Nel mezzo,\n",
      "\n",
      "per ch’a pena il pertullo aere,\n",
      "quando si provedenza, che apparieno\n",
      "con li altri pescüagliaia si rigisse.\n",
      "\n",
      "«Se tu che tu non\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  72%|███████▏  | 962/1344 [02:13<02:02,  3.12it/s, loss=2.99]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 960]\n",
      "Nel mezzo cerchio co’ vivi.\n",
      "\n",
      "E io dissi: «Se tu colui che ti mena?\n",
      "che questi che per li occhi miei siedi,\n",
      "e vedracciati li occhi ver’ noi a te stesso:\n",
      "\n",
      "però siam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  74%|███████▍  | 992/1344 [02:17<02:00,  2.93it/s, loss=2.98]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 990]\n",
      "Nel mezzo ’l ciel non si movea\n",
      "\n",
      "sì ch’ella fui di me, che non si nasconde\n",
      "non suonan da sé, ma fuor carità non scuovo,\n",
      "\n",
      "che di sopra voler voler lor pastura,\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  76%|███████▌  | 1022/1344 [02:21<02:05,  2.57it/s, loss=2.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 1020]\n",
      "Nel mezzo,\n",
      "per non esser cagione a la veduta\n",
      "\n",
      "rimbomba, ma per la mente truce\n",
      "di sua circïenza avea già resplende,\n",
      "e d’un pan sembiante maestro:\n",
      "ché ’l\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  78%|███████▊  | 1050/1344 [02:24<00:26, 11.29it/s, loss=3.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 1050]\n",
      "Nel mezzo\n",
      "de l’alto scende, ond’ io mossi li disfatto;\n",
      "\n",
      "l’un converso per la mia nota mente;\n",
      "per ch’io: «Figlio che sia non son colui?’.\n",
      "\n",
      "Madonna, per\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  81%|████████  | 1082/1344 [02:31<01:39,  2.63it/s, loss=2.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 1080]\n",
      "Nel mezzo cerchio,\n",
      "\n",
      "sente incominciò: «Drizza, e questo manto:\n",
      "questi vuol che s’acqui sia sì poco,\n",
      "che se’ tu mi ancora di fuori».\n",
      "\n",
      "Come ’l foco che ’nte\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  83%|████████▎ | 1112/1344 [02:35<01:20,  2.90it/s, loss=2.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 1110]\n",
      "Nel mezzo ad una versa age a li occhi ch’al ver di Cristo,\n",
      "\n",
      "infin che l’ordine ch’appoggio,\n",
      "ma non farebbe il viso a tanto,\n",
      "con buona obe di sé l’\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  85%|████████▍ | 1142/1344 [02:39<01:13,  2.73it/s, loss=2.84]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 1140]\n",
      "Nel mezzo.\n",
      "\n",
      "Ivi è l’ha come l’ali aperte,\n",
      "così, a pena fuoro angeli che son rifosco;\n",
      "poi cerchi mostrar ciò ch’è in sù più volte».\n",
      "\n",
      "E io rispuosi lei:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  87%|████████▋ | 1172/1344 [02:43<00:54,  3.15it/s, loss=2.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 1170]\n",
      "Nel mezzo\n",
      "per l’aere a sé, e ciascuna in me ramplo,\n",
      "come il cielo il sole e ’l suo imperchio».\n",
      "\n",
      "Poscia trasse a me: «Dio pensava così scïenza:\n",
      "se non ti\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  89%|████████▉ | 1202/1344 [02:47<00:41,  3.43it/s, loss=2.87]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 1200]\n",
      "Nel mezzo cerchio co’ suoi diede.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Inferno\n",
      "Canto XXI\n",
      "\n",
      "\n",
      "«Sovra Cin, quando l’ora del mio»,\n",
      "cominciò el, «e ’l duca mio, quest’ ho viso:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  92%|█████████▏| 1232/1344 [02:52<00:39,  2.85it/s, loss=2.86]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 1230]\n",
      "Nel mezzo di neve\n",
      "di lor modo che ’l suo mal de l’ardosta.\n",
      "\n",
      "Vostroccisi dunque, con l’occhio rivo\n",
      "fossero augelletto di colui che vede\n",
      "cotai le membra del sole a\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  94%|█████████▍| 1262/1344 [02:56<00:26,  3.05it/s, loss=2.82]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 1260]\n",
      "Nel mezzo\n",
      "su per li occhi al ciel, che l’uom che ministra\n",
      "ne l’etterno staturo, in ciò ch’a te si torce.\n",
      "\n",
      "Io stava come già dritto appariva\n",
      "per la sua virtute\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  96%|█████████▌| 1292/1344 [02:59<00:16,  3.12it/s, loss=2.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 1290]\n",
      "Nel mezzo, or di poggio scusa\n",
      "la lunga vita e d'uom digiunsa;\n",
      "sì come al mio dir m'importuna nebbia\n",
      "volse da tutti, e guardato, a tanto avanza.\n",
      "A la mia vita\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  98%|█████████▊| 1322/1344 [03:03<00:07,  3.10it/s, loss=2.77]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample @ epoch 1, batch 1320]\n",
      "Nel mezzo.\n",
      "\n",
      "Tosto che tutto quanto posso a le foglie\n",
      "le man nostre cibietto il ver né l’anno,\n",
      "e più d’un modo tutto l’altro basso,\n",
      "\n",
      "quando l’animo mio tra ’l\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 1344/1344 [03:05<00:00,  7.25it/s, loss=2.92]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished. Average loss: 3.1405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test the model",
   "id": "51606a98f407b5a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T21:54:13.149237Z",
     "start_time": "2025-04-24T21:54:05.526503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## evaluate model\n",
    "model.eval()\n",
    "start_text = \"Nel mezzo del cammin di nostra \"\n",
    "start_ids = tokenizer.encode(start_text).ids\n",
    "input_ids = torch.tensor([start_ids], device=device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=200,\n",
    "    temperature=1.0,\n",
    "    top_k=20\n",
    ")\n",
    "\n",
    "decoded = tokenizer.decode(generated_ids[0].tolist())\n",
    "print(start_text+f\"{decoded}\\n\")"
   ],
   "id": "196f379489040ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nel mezzo del cammin di nostra , come ferma ruba, e però l’abbia;\n",
      "\n",
      "ché ciascun di lor quattro animai si sazia\n",
      "da lui di là dal sonno, s’adempio\n",
      "e permutava in su l’articini.\n",
      "\n",
      "Poi appresso in quella parte onde s’ama,\n",
      "come ’l buon duca, non si mosse; ma\n",
      "però che la ripa fa scema.\n",
      "\n",
      "«S’ogne malizia ti dà, perché ’l ti redeste?».\n",
      "E «Giauro misero Secognazïaco\n",
      "che ’n su le spalle al\n",
      "\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Not too bad for something that was trained on a laptop for less tha 10 minutes. It can form sensible italian words and has a reasonable structure that resembles the input text. It also learned grammar rules, how to use punctiation etc. With more data and a slightly more complicated model, it could be even better, perhaps creating actually good poetry.",
   "id": "db3b9daba8f48a61"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
